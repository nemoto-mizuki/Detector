2023-01-19 14:13:03,900   INFO  **********************Start logging**********************
2023-01-19 14:13:03,900   INFO  CUDA_VISIBLE_DEVICES=1
2023-01-19 14:13:03,901   INFO  cfg_file         tools/cfgs/waymo_models/swin_center_ver2.yaml
2023-01-19 14:13:03,901   INFO  batch_size       2
2023-01-19 14:13:03,901   INFO  epochs           10
2023-01-19 14:13:03,901   INFO  full_params_epochs None
2023-01-19 14:13:03,901   INFO  workers          8
2023-01-19 14:13:03,901   INFO  extra_tag        20230111
2023-01-19 14:13:03,901   INFO  ckpt             None
2023-01-19 14:13:03,901   INFO  pretrained_model /media/Elements/nemoto/OpenPCDet_old/output/media/Elements/nemoto/OpenPCDet/tools/cfgs/waymo_models/centerpoint/default/ckpt/checkpoint_epoch_50.pth
2023-01-19 14:13:03,901   INFO  launcher         none
2023-01-19 14:13:03,901   INFO  tcp_port         18888
2023-01-19 14:13:03,901   INFO  sync_bn          False
2023-01-19 14:13:03,901   INFO  fix_random_seed  False
2023-01-19 14:13:03,902   INFO  ckpt_save_interval 1
2023-01-19 14:13:03,902   INFO  local_rank       0
2023-01-19 14:13:03,902   INFO  max_ckpt_save_num 30
2023-01-19 14:13:03,902   INFO  merge_all_iters_to_one_epoch False
2023-01-19 14:13:03,902   INFO  set_cfgs         None
2023-01-19 14:13:03,902   INFO  data_parallel    False
2023-01-19 14:13:03,902   INFO  max_waiting_mins 0
2023-01-19 14:13:03,902   INFO  start_epoch      0
2023-01-19 14:13:03,902   INFO  num_epochs_to_eval 0
2023-01-19 14:13:03,902   INFO  save_to_file     False
2023-01-19 14:13:03,902   INFO  use_tqdm_to_record True
2023-01-19 14:13:03,902   INFO  logger_iter_interval 50
2023-01-19 14:13:03,902   INFO  ckpt_save_time_interval 300
2023-01-19 14:13:03,903   INFO  wo_gpu_stat      False
2023-01-19 14:13:03,903   INFO  cfg.ROOT_DIR: /media/WD6THDD/Detector
2023-01-19 14:13:03,903   INFO  cfg.LOCAL_RANK: 0
2023-01-19 14:13:03,903   INFO  cfg.CLASS_NAMES: ['Vehicle', 'Pedestrian', 'Cyclist']
2023-01-19 14:13:03,903   INFO  
cfg.DATA_CONFIG = edict()
2023-01-19 14:13:03,903   INFO  cfg.DATA_CONFIG.DATASET: WaymoDataset
2023-01-19 14:13:03,903   INFO  cfg.DATA_CONFIG.DATA_PATH: /media/WD6THDD/Detector/data/waymo
2023-01-19 14:13:03,903   INFO  cfg.DATA_CONFIG.PROCESSED_DATA_TAG: waymo_processed_data_v0_5_0
2023-01-19 14:13:03,903   INFO  cfg.DATA_CONFIG.POINT_CLOUD_RANGE: [-75.2, -75.2, -2, 75.2, 75.2, 4]
2023-01-19 14:13:03,903   INFO  
cfg.DATA_CONFIG.DATA_SPLIT = edict()
2023-01-19 14:13:03,903   INFO  cfg.DATA_CONFIG.DATA_SPLIT.train: train
2023-01-19 14:13:03,903   INFO  cfg.DATA_CONFIG.DATA_SPLIT.test: val
2023-01-19 14:13:03,904   INFO  
cfg.DATA_CONFIG.SAMPLED_INTERVAL = edict()
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SAMPLED_INTERVAL.train: 2
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SAMPLED_INTERVAL.test: 5
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.FILTER_EMPTY_BOXES_FOR_TRAIN: True
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.DISABLE_NLZ_FLAG_ON_POINTS: True
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.USE_SHARED_MEMORY: False
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SHARED_MEMORY_FILE_LIMIT: 35000
2023-01-19 14:13:03,904   INFO  
cfg.DATA_CONFIG.SEQUENCE_CONFIG = edict()
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SEQUENCE_CONFIG.ENABLED: True
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SEQUENCE_CONFIG.SAMPLE_OFFSET: [-3, 0]
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SEQUENCE_CONFIG.SAMPLE_INTERVAL: 1
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SEQUENCE_CONFIG.ONEHOT_TIMESTAMP: False
2023-01-19 14:13:03,904   INFO  cfg.DATA_CONFIG.SEQUENCE_CONFIG.SPLIT_DATA: True
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.SEQUENCE_CONFIG.SPLIT_SEQUENCE_LIST: True
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.TRAIN_WITH_SPEED: True
2023-01-19 14:13:03,905   INFO  
cfg.DATA_CONFIG.DATA_AUGMENTOR = edict()
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.DISABLE_AUG_LIST: ['placeholder']
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.DATA_AUGMENTOR.AUG_CONFIG_LIST: [{'NAME': 'gt_sampling', 'USE_ROAD_PLANE': False, 'DB_INFO_PATH': ['waymo_processed_data_v0_5_0_waymo_dbinfos_train_sampled_1_multiframe_-4_to_0.pkl'], 'USE_SHARED_MEMORY': False, 'DB_DATA_PATH': ['waymo_processed_data_v0_5_0_gt_database_train_sampled_1_multiframe_-4_to_0_global.npy'], 'PREPARE': {'filter_by_min_points': ['Vehicle:5', 'Pedestrian:5', 'Cyclist:5'], 'filter_by_difficulty': [-1]}, 'SAMPLE_GROUPS': ['Vehicle:15', 'Pedestrian:10', 'Cyclist:10'], 'NUM_POINT_FEATURES': 6, 'REMOVE_EXTRA_WIDTH': [0.0, 0.0, 0.0], 'LIMIT_WHOLE_SCENE': True, 'FILTER_OBJ_POINTS_BY_TIMESTAMP': True, 'TIME_RANGE': [0.3, 0.0]}, {'NAME': 'random_world_flip', 'ALONG_AXIS_LIST': ['x', 'y']}, {'NAME': 'random_world_rotation', 'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]}, {'NAME': 'random_world_scaling', 'WORLD_SCALE_RANGE': [0.95, 1.05]}]
2023-01-19 14:13:03,905   INFO  
cfg.DATA_CONFIG.POINT_FEATURE_ENCODING = edict()
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.encoding_type: absolute_coordinates_encoding
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.used_feature_list: ['x', 'y', 'z', 'intensity', 'elongation', 'timestamp']
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.POINT_FEATURE_ENCODING.src_feature_list: ['x', 'y', 'z', 'intensity', 'elongation', 'timestamp']
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG.DATA_PROCESSOR: [{'NAME': 'mask_points_and_boxes_outside_range', 'REMOVE_OUTSIDE_BOXES': True, 'USE_CENTER_TO_FILTER': True}, {'NAME': 'shuffle_points', 'SHUFFLE_ENABLED': {'train': True, 'test': True}}, {'NAME': 'transform_points_to_voxels', 'VOXEL_SIZE': [0.1, 0.1, 0.15], 'MAX_POINTS_PER_VOXEL': 5, 'MAX_NUMBER_OF_VOXELS': {'train': 180000, 'test': 400000}}]
2023-01-19 14:13:03,905   INFO  cfg.DATA_CONFIG._BASE_CONFIG_: tools/cfgs/dataset_configs/waymo_dataset_multiframe.yaml
2023-01-19 14:13:03,905   INFO  
cfg.MODEL = edict()
2023-01-19 14:13:03,906   INFO  cfg.MODEL.NAME: SA_CenterPoint
2023-01-19 14:13:03,906   INFO  
cfg.MODEL.VFE = edict()
2023-01-19 14:13:03,906   INFO  cfg.MODEL.VFE.NAME: MeanVFEMultiframe
2023-01-19 14:13:03,906   INFO  
cfg.MODEL.BACKBONE_3D = edict()
2023-01-19 14:13:03,906   INFO  cfg.MODEL.BACKBONE_3D.NAME: VoxelResBackBone8xMultiFrame
2023-01-19 14:13:03,906   INFO  
cfg.MODEL.MAP_TO_BEV = edict()
2023-01-19 14:13:03,906   INFO  cfg.MODEL.MAP_TO_BEV.NAME: HeightCompressionMulti
2023-01-19 14:13:03,906   INFO  cfg.MODEL.MAP_TO_BEV.NUM_BEV_FEATURES: 256
2023-01-19 14:13:03,906   INFO  
cfg.MODEL.BACKBONE_2D = edict()
2023-01-19 14:13:03,906   INFO  cfg.MODEL.BACKBONE_2D.NAME: BaseBEVBackboneMulti_ver2
2023-01-19 14:13:03,906   INFO  cfg.MODEL.BACKBONE_2D.LAYER_NUMS: [5, 5]
2023-01-19 14:13:03,906   INFO  cfg.MODEL.BACKBONE_2D.LAYER_STRIDES: [1, 2]
2023-01-19 14:13:03,906   INFO  cfg.MODEL.BACKBONE_2D.NUM_FILTERS: [128, 256]
2023-01-19 14:13:03,907   INFO  cfg.MODEL.BACKBONE_2D.UPSAMPLE_STRIDES: [1, 2]
2023-01-19 14:13:03,907   INFO  cfg.MODEL.BACKBONE_2D.NUM_UPSAMPLE_FILTERS: [256, 256]
2023-01-19 14:13:03,907   INFO  
cfg.MODEL.DENSE_HEAD = edict()
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.NAME: SwinCenterHead
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.CLASS_AGNOSTIC: False
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.CLASS_NAMES_EACH_HEAD: [['Vehicle', 'Pedestrian', 'Cyclist']]
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.SHARED_CONV_CHANNEL: 64
2023-01-19 14:13:03,907   INFO  
cfg.MODEL.DENSE_HEAD.TRANSFORMAR = edict()
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.pretrained: None
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.pretrained2d: None
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.patch_size: [1, 1, 1]
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.in_chans: 64
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.embed_dim: 64
2023-01-19 14:13:03,907   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.depths: [6]
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.num_heads: [8]
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.window_size: [2, 7, 7]
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.mlp_ratio: 4.0
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.qkv_bias: True
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.qk_scale: None
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.drop_rate: 0.0
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.attn_drop_rate: 0.0
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.drop_path_rate: 0.2
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.norm_layer: LayerNorm
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.patch_norm: False
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.frozen_stages: -1
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.TRANSFORMAR.use_checkpoint: False
2023-01-19 14:13:03,908   INFO  cfg.MODEL.DENSE_HEAD.USE_BIAS_BEFORE_NORM: True
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.NUM_HM_CONV: 2
2023-01-19 14:13:03,909   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG = edict()
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_ORDER: ['center', 'center_z', 'dim', 'rot', 'vel']
2023-01-19 14:13:03,909   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT = edict()
2023-01-19 14:13:03,909   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center = edict()
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.out_channels: 2
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center.num_conv: 2
2023-01-19 14:13:03,909   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z = edict()
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z.out_channels: 1
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.center_z.num_conv: 2
2023-01-19 14:13:03,909   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim = edict()
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.out_channels: 3
2023-01-19 14:13:03,909   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.dim.num_conv: 2
2023-01-19 14:13:03,910   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot = edict()
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.out_channels: 2
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.rot.num_conv: 2
2023-01-19 14:13:03,910   INFO  
cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel = edict()
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.out_channels: 2
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.SEPARATE_HEAD_CFG.HEAD_DICT.vel.num_conv: 2
2023-01-19 14:13:03,910   INFO  
cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG = edict()
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.FEATURE_MAP_STRIDE: 8
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.NUM_MAX_OBJS: 500
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.GAUSSIAN_OVERLAP: 0.1
2023-01-19 14:13:03,910   INFO  cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG.MIN_RADIUS: 2
2023-01-19 14:13:03,910   INFO  
cfg.MODEL.DENSE_HEAD.LOSS_CONFIG = edict()
2023-01-19 14:13:03,910   INFO  
cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS = edict()
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.cls_weight: 1.0
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.loc_weight: 5.0
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.LOSS_CONFIG.LOSS_WEIGHTS.code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2]
2023-01-19 14:13:03,911   INFO  
cfg.MODEL.DENSE_HEAD.POST_PROCESSING = edict()
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.SCORE_THRESH: 0.1
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.POST_CENTER_LIMIT_RANGE: [-75.2, -75.2, -2, 75.2, 75.2, 4]
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.MAX_OBJ_PER_SAMPLE: 500
2023-01-19 14:13:03,911   INFO  
cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG = edict()
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_TYPE: nms_gpu
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_THRESH: 0.7
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_PRE_MAXSIZE: 4096
2023-01-19 14:13:03,911   INFO  cfg.MODEL.DENSE_HEAD.POST_PROCESSING.NMS_CONFIG.NMS_POST_MAXSIZE: 500
2023-01-19 14:13:03,911   INFO  
cfg.MODEL.POST_PROCESSING = edict()
2023-01-19 14:13:03,912   INFO  cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
2023-01-19 14:13:03,912   INFO  cfg.MODEL.POST_PROCESSING.EVAL_METRIC: waymo
2023-01-19 14:13:03,912   INFO  
cfg.OPTIMIZATION = edict()
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.BATCH_SIZE_PER_GPU: 2
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.NUM_EPOCHS: 10
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.OPTIMIZER: adam_onecycle
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.LR: 0.003
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.WEIGHT_DECAY: 0.01
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.MOMENTUM: 0.9
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.MOMS: [0.95, 0.85]
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.PCT_START: 0.4
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.DIV_FACTOR: 10
2023-01-19 14:13:03,912   INFO  cfg.OPTIMIZATION.DECAY_STEP_LIST: [35, 45]
2023-01-19 14:13:03,913   INFO  cfg.OPTIMIZATION.LR_DECAY: 0.1
2023-01-19 14:13:03,913   INFO  cfg.OPTIMIZATION.LR_CLIP: 1e-07
2023-01-19 14:13:03,913   INFO  cfg.OPTIMIZATION.LR_WARMUP: False
2023-01-19 14:13:03,913   INFO  cfg.OPTIMIZATION.WARMUP_EPOCH: 1
2023-01-19 14:13:03,913   INFO  cfg.OPTIMIZATION.GRAD_NORM_CLIP: 10
2023-01-19 14:13:03,913   INFO  cfg.TAG: swin_center_ver2
2023-01-19 14:13:03,913   INFO  cfg.EXP_GROUP_PATH: waymo_models
2023-01-19 14:13:17,857   INFO  Database filter by min points Vehicle: 1194368 => 1098210
2023-01-19 14:13:18,110   INFO  Database filter by min points Pedestrian: 1114091 => 1025350
2023-01-19 14:13:18,132   INFO  Database filter by min points Cyclist: 53344 => 49577
2023-01-19 14:13:18,502   INFO  Database filter by difficulty Vehicle: 1098210 => 1098210
2023-01-19 14:13:18,846   INFO  Database filter by difficulty Pedestrian: 1025350 => 1025350
2023-01-19 14:13:18,862   INFO  Database filter by difficulty Cyclist: 49577 => 49577
2023-01-19 14:13:19,114   INFO  Loading Waymo dataset
2023-01-19 14:13:54,643   INFO  Total skipped info 0
2023-01-19 14:13:54,643   INFO  Total samples for Waymo dataset: 158081
2023-01-19 14:13:54,658   INFO  Total sampled samples for Waymo dataset: 79041
2023-01-19 14:14:01,092   INFO  ==> Loading parameters from checkpoint /media/Elements/nemoto/OpenPCDet_old/output/media/Elements/nemoto/OpenPCDet/tools/cfgs/waymo_models/centerpoint/default/ckpt/checkpoint_epoch_50.pth to GPU
2023-01-19 14:14:21,057   INFO  ==> Checkpoint trained from version: pcdet+0.5.1+1f5b787
2023-01-19 14:14:21,100   INFO  Not updated weight backbone_3d.conv_input.0.weight: torch.Size([16, 3, 3, 3, 6])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.patch_embed.proj.weight: torch.Size([64, 64, 1, 1, 1])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.patch_embed.proj.bias: torch.Size([64])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.norm1.weight: torch.Size([64])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.norm1.bias: torch.Size([64])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.attn.relative_position_bias_table: torch.Size([507, 8])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.attn.relative_position_index: torch.Size([98, 98])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.attn.qkv.weight: torch.Size([192, 64])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.attn.qkv.bias: torch.Size([192])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.attn.proj.weight: torch.Size([64, 64])
2023-01-19 14:14:21,101   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.attn.proj.bias: torch.Size([64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.norm2.weight: torch.Size([64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.norm2.bias: torch.Size([64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.mlp.fc1.weight: torch.Size([256, 64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.mlp.fc1.bias: torch.Size([256])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.mlp.fc2.weight: torch.Size([64, 256])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.0.mlp.fc2.bias: torch.Size([64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.norm1.weight: torch.Size([64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.norm1.bias: torch.Size([64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.attn.relative_position_bias_table: torch.Size([507, 8])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.attn.relative_position_index: torch.Size([98, 98])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.attn.qkv.weight: torch.Size([192, 64])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.attn.qkv.bias: torch.Size([192])
2023-01-19 14:14:21,102   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.attn.proj.weight: torch.Size([64, 64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.attn.proj.bias: torch.Size([64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.norm2.weight: torch.Size([64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.norm2.bias: torch.Size([64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.mlp.fc1.weight: torch.Size([256, 64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.mlp.fc1.bias: torch.Size([256])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.mlp.fc2.weight: torch.Size([64, 256])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.1.mlp.fc2.bias: torch.Size([64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.norm1.weight: torch.Size([64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.norm1.bias: torch.Size([64])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.attn.relative_position_bias_table: torch.Size([507, 8])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.attn.relative_position_index: torch.Size([98, 98])
2023-01-19 14:14:21,103   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.attn.qkv.weight: torch.Size([192, 64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.attn.qkv.bias: torch.Size([192])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.attn.proj.weight: torch.Size([64, 64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.attn.proj.bias: torch.Size([64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.norm2.weight: torch.Size([64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.norm2.bias: torch.Size([64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.mlp.fc1.weight: torch.Size([256, 64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.mlp.fc1.bias: torch.Size([256])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.mlp.fc2.weight: torch.Size([64, 256])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.2.mlp.fc2.bias: torch.Size([64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.norm1.weight: torch.Size([64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.norm1.bias: torch.Size([64])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.attn.relative_position_bias_table: torch.Size([507, 8])
2023-01-19 14:14:21,104   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.attn.relative_position_index: torch.Size([98, 98])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.attn.qkv.weight: torch.Size([192, 64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.attn.qkv.bias: torch.Size([192])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.attn.proj.weight: torch.Size([64, 64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.attn.proj.bias: torch.Size([64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.norm2.weight: torch.Size([64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.norm2.bias: torch.Size([64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.mlp.fc1.weight: torch.Size([256, 64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.mlp.fc1.bias: torch.Size([256])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.mlp.fc2.weight: torch.Size([64, 256])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.3.mlp.fc2.bias: torch.Size([64])
2023-01-19 14:14:21,105   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.norm1.weight: torch.Size([64])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.norm1.bias: torch.Size([64])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.attn.relative_position_bias_table: torch.Size([507, 8])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.attn.relative_position_index: torch.Size([98, 98])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.attn.qkv.weight: torch.Size([192, 64])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.attn.qkv.bias: torch.Size([192])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.attn.proj.weight: torch.Size([64, 64])
2023-01-19 14:14:21,106   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.attn.proj.bias: torch.Size([64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.norm2.weight: torch.Size([64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.norm2.bias: torch.Size([64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.mlp.fc1.weight: torch.Size([256, 64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.mlp.fc1.bias: torch.Size([256])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.mlp.fc2.weight: torch.Size([64, 256])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.4.mlp.fc2.bias: torch.Size([64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.norm1.weight: torch.Size([64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.norm1.bias: torch.Size([64])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.attn.relative_position_bias_table: torch.Size([507, 8])
2023-01-19 14:14:21,107   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.attn.relative_position_index: torch.Size([98, 98])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.attn.qkv.weight: torch.Size([192, 64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.attn.qkv.bias: torch.Size([192])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.attn.proj.weight: torch.Size([64, 64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.attn.proj.bias: torch.Size([64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.norm2.weight: torch.Size([64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.norm2.bias: torch.Size([64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.mlp.fc1.weight: torch.Size([256, 64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.mlp.fc1.bias: torch.Size([256])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.mlp.fc2.weight: torch.Size([64, 256])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.layers.0.blocks.5.mlp.fc2.bias: torch.Size([64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.norm.weight: torch.Size([64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.transformer.norm.bias: torch.Size([64])
2023-01-19 14:14:21,108   INFO  Not updated weight dense_head.heads_list.0.vel.0.0.weight: torch.Size([64, 64, 3, 3])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.0.0.bias: torch.Size([64])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.0.1.weight: torch.Size([64])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.0.1.bias: torch.Size([64])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.0.1.running_mean: torch.Size([64])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.0.1.running_var: torch.Size([64])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.0.1.num_batches_tracked: torch.Size([])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.1.weight: torch.Size([2, 64, 3, 3])
2023-01-19 14:14:21,109   INFO  Not updated weight dense_head.heads_list.0.vel.1.bias: torch.Size([2])
2023-01-19 14:14:21,109   INFO  ==> Done (loaded 278/376)
2023-01-19 14:14:21,110   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_10.pth to GPU
2023-01-19 14:14:21,429   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/latest_model.pth to GPU
2023-01-19 14:14:21,702   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_9.pth to GPU
2023-01-19 14:14:22,054   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_8.pth to GPU
2023-01-19 14:14:22,356   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_7.pth to GPU
2023-01-19 14:14:22,647   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_6.pth to GPU
2023-01-19 14:14:22,941   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_5.pth to GPU
2023-01-19 14:14:23,257   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_4.pth to GPU
2023-01-19 14:14:23,565   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_3.pth to GPU
2023-01-19 14:14:23,857   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_2.pth to GPU
2023-01-19 14:14:24,180   INFO  ==> Loading parameters from checkpoint /media/WD6THDD/Detector/out_dir/waymo_models/swin_center_ver2/20230111/ckpt/checkpoint_epoch_1.pth to GPU
2023-01-19 14:14:24,473   INFO  SelfAttentionCenterPoint(
  (vfe): MeanVFEMulti()
  (backbone_3d): VoxelResBackBone8x_multiframe(
    (conv_input): SparseSequential(
      (0): SubMConv3d(6, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (conv1): SparseSequential(
      (0): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv2): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv3): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv4): SparseSequential(
      (0): SparseSequential(
        (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
      (2): SparseBasicBlock(
        (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (relu): ReLU()
        (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)
        (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      )
    )
    (conv_out): SparseSequential(
      (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)
      (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (map_to_bev_module): HeightCompressionMulti()
  (pfe): None
  (self_attention_module): None
  (backbone_2d): BaseBEVBackboneMulti_ver2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
  )
  (dense_head): SwinCenterHead(
    (shared_conv): Sequential(
      (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (transformer): SwinTransformer3D(
      (patch_embed): PatchEmbed3D(
        (proj): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock3D(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=64, out_features=192, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=256, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=256, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock3D(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=64, out_features=192, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.040)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=256, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=256, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock3D(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=64, out_features=192, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.080)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=256, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=256, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock3D(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=64, out_features=192, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.120)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=256, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=256, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock3D(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=64, out_features=192, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.160)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=256, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=256, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock3D(
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention3D(
                (qkv): Linear(in_features=64, out_features=192, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.200)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=64, out_features=256, bias=True)
                (act): GELU()
                (fc2): Linear(in_features=256, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (heads_list): ModuleList(
      (0): SeparateHead(
        (center): Sequential(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (center_z): Sequential(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (dim): Sequential(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (rot): Sequential(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (vel): Sequential(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (hm): Sequential(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU()
          )
          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (hm_loss_func): FocalLossCenterNet()
    (reg_loss_func): RegLossCenterNet()
  )
  (point_head): None
  (roi_head): None
)
2023-01-19 14:14:24,478   INFO  **********************Start training waymo_models/swin_center_ver2(20230111)**********************
